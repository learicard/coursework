{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement a diagonal Gaussian parametric density estimator. It will\n",
    "have to work for data of arbitrary dimension d. As seen in the labs, it\n",
    "should have a train() method to learn the parameters and a method\n",
    "predict() which calculates the log density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "\n",
    "class diagonal_gaussian_parametric:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_inputs):\n",
    "        \n",
    "        # if only one training dimension is passed, add dummy dimension\n",
    "        if len(np.shape(train_inputs)) == 1:\n",
    "            train_inputs = np.expand_dims(train_inputs, axis=1).T\n",
    "\n",
    "        self.train_inputs = train_inputs\n",
    "        self.n, self.d = np.shape(self.train_inputs)\n",
    "\n",
    "        self.mu = np.sum(self.train_inputs, axis=0) / self.n\n",
    "        self.sigma = np.cov(self.train_inputs.T) * np.eye(self.d)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "\n",
    "        # if only one test_data is passed, add dummy dimension\n",
    "        if len(np.shape(test_data)) == 1:\n",
    "            test_data = np.expand_dims(test_data, axis=1).T\n",
    "\n",
    "        self.test_data = test_data\n",
    "        n_inputs = np.shape(test_data)[0]\n",
    "        densities = np.zeros(n_inputs)\n",
    "        \n",
    "        normalizer = 1 / ((2* np.pi)**(self.d / 2) * np.sqrt(sigma_det))\n",
    "\n",
    "        # we treat each input test_data independently\n",
    "        for i in range(n_inputs):\n",
    "            \n",
    "            sigma_inv = np.linalg.inv(self.sigma)\n",
    "            sigma_det = np.linalg.det(self.sigma)\n",
    "\n",
    "            exponent = (-0.5) * (self.test_data[i, :] - self.mu).T.dot(sigma_inv).dot(self.test_data[i, :] - self.mu)\n",
    "            p = normalizer*np.exp(exponent)\n",
    "            \n",
    "            # handle edge case where p(x)=0\n",
    "            if p == 0:\n",
    "                p = np.finfo(float).eps\n",
    "                \n",
    "            densities[i] = -np.log(p)\n",
    "        \n",
    "        return(densities)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.26788439 36.04365339]\n",
      "[37.26788439]\n"
     ]
    }
   ],
   "source": [
    "iris = np.loadtxt(\"iris.txt\")\n",
    "test = diagonal_gaussian_parametric()\n",
    "test.train(iris)\n",
    "\n",
    "test_data = np.array([[1,2,3,4,5], [2,30,40,50,60]])\n",
    "print(test.predict(test_data))\n",
    "\n",
    "test_data = np.array([1,2,3,4,5])\n",
    "print(test.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement a Parzen density estimator with an isotropic Gaussian kernel.\n",
    "It will have to work for data of arbitrary dimension d. Likewise it\n",
    "should have a train() method and a predict() method that computes\n",
    "the log density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class parzen_density_estimator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, train_inputs, sigma=0):\n",
    "        self.train_data = train_inputs\n",
    "        self.d = len(self.train_data[0])\n",
    "        \n",
    "        if sigma == 0:\n",
    "            self.sigma = np.std(self.train_data) # std because isotropic Gaussian\n",
    "        else:\n",
    "            self.sigma = sigma\n",
    "            \n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        # if only one test_data is passed, add dummy dimension\n",
    "        if len(np.shape(test_data)) == 1:\n",
    "            test_data = np.expand_dims(test_data, axis=1).T\n",
    "\n",
    "        self.test_data = test_data\n",
    "        n_inputs = np.shape(test_data)[0]\n",
    "        n_train = np.shape(self.train_data)[0]\n",
    "        densities = np.zeros(n_inputs)\n",
    "        \n",
    "        normalizer = 1 / ((2*np.pi)**(self.d / 2) * self.sigma**self.d)\n",
    "            \n",
    "        for i in range(n_inputs): \n",
    "            \n",
    "            # calculate average distance between this training point and all test points\n",
    "            p = 0 \n",
    "            for j in range(n_train):\n",
    "            \n",
    "                # we're using euclidean distance\n",
    "                distance = np.sum(self.test_data[i, :] - self.train_data[j, :], axis=0)**2\n",
    "                exponent = (-0.5) * (distance**2 / self.sigma**2)\n",
    "                p += normalizer*np.exp(exponent)\n",
    "            \n",
    "            # handle edge case where p(x)=0\n",
    "            if p == 0:\n",
    "                p = np.finfo(float).eps\n",
    "                \n",
    "            # save the average kernel values across all training points\n",
    "            densities[i] = -np.log(p/n_train)\n",
    "        \n",
    "            \n",
    "        return(densities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.57305544 41.05428868]\n",
      "[9.57305544]\n"
     ]
    }
   ],
   "source": [
    "iris = np.loadtxt(\"iris.txt\")\n",
    "test = parzen_density_estimator()\n",
    "test.train(iris)\n",
    "\n",
    "\n",
    "test_data = np.array([[1,2,3,4,5], [2,30,40,50,60]])\n",
    "print(test.predict(test_data))\n",
    "\n",
    "test_data = np.array([1,2,3,4,5])\n",
    "print(test.predict(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D densities: From the Iris dataset examples, choose a subset corresponding\n",
    "to one of the classes (of your choice), and one of the characteristic\n",
    "features, so that we will be in dimension d = 1 and produce a\n",
    "single graph (using the plot function) including:\n",
    "\n",
    "(a) the data points of the subset (displayed on the x axis).\n",
    "(b) a plot of the density estimated by your parametric Gaussian estimator.\n",
    "(c) a plot of the density estimated by the Parzen estimator with a\n",
    "hyper-parameter σ (standard deviation) too small.\n",
    "(d) a plot of the density estimated by the Parzen estimator with the\n",
    "hyper-parameter σ being a little too big.\n",
    "(e) a plot of the density estimated by the Parzen estimator with the\n",
    "hyper-parameter σ that you consider more appropriate. Use a\n",
    "different color for each plot, and provide your graph with a clear\n",
    "legend.\n",
    "(f) Explain how you chose your hyper-parameter σ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = np.leadtxt(\"iris.txt\")\n",
    "iris_subset = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2D densities: Now add a second characteristic feature of Iris, in order\n",
    "to have entries in d = 2 and produce 4 plots, each displaying the points\n",
    "of the subset of the data (with the plot function ), and the contour\n",
    "lines of the density estimated (using the contour function):\n",
    "    \n",
    "(a) by the diagonal Gaussian parametric estimator.\n",
    "(b) by the Parzen estimator with the hyper-parameter σ (standard\n",
    "deviation ) being too small.\n",
    "(c) by the Parzen estimator with the hyper-parameter σ being a little\n",
    "too big.\n",
    "(d) by the Parzen estimator with the hyper-parameter σ that you\n",
    "consider more appropriate.\n",
    "(e) Explain how you chose your hyper-parameter σ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
