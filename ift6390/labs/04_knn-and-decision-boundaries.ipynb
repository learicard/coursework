{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo 4 (solutions): KNN, Training and Test set, Decision boundaries. 20/09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week you implemented the 1 nearest neighbor (1NN) algorithm. This week you will implement the KNN algorithm. On top of this, we will also touch upon training and test sets, as well as decision boundary.\n",
    "\n",
    "- Your first step is to remember how KNN works.\n",
    "- We provide you with the boilerplate code in which you will need to insert your KNN implementation. This way you will be able to focus on the actual algorithm itself and not have to worry about such things as printing or displaying results.\n",
    "- You can execute each cell by clicking on Cell/Run all: On the last cell you will observe a constant classifier (which also predicts, regardless of its input, class 1 (blue))\n",
    "\n",
    "Familiarize yourself with the code in the following 5 sections:\n",
    "   - **Utility Functions:** Defines helper functions such as for visualization, evaluation, etc.\n",
    "   - **KNN class:** This is where you will implement the classifier.\n",
    "   - **Loading and splitting the data:** Loads a dataset and splits it into two parts (train, test)\n",
    "   - **Initialization and training of classifier:** Trains a KNN model on the train dataset and obtains predictions on the test set\n",
    "   - **Confusion matrix and decision boundary:** Displays the confusion matrix and visualizes the decision boundary of our trained classifier\n",
    "\n",
    "**Your objective for this demo session** is to understand the general functioning of the code below and then to fill in the function knn.compute_predictions()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we will implement KNN as a **class**. You can read this [tutorial](http://docs.python.org/2/tutorial/classes.html) if you are not familiar with the concept of classes in Object-oriented programming or its syntax in python. The class `knn` is already partially implemented. All that you have left to do is to write the method `compute_predictions`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not have anything to implement here. Simply read the code and familiarize yourelf with it. You will be able to test the functions `test` and `gridplot` at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pylab inline\n",
    "import numpy as np\n",
    "import random\n",
    "import pylab\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions calculates the Minkowski distance between a vector x and a matrix Y. Does this remind you of anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_mat(x,Y,p=2):\n",
    "    return (np.sum((np.abs(x-Y))**p,axis=1))**(1.0/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `conf_matrix` takes as input:\n",
    "\n",
    "- `testlabels` - test labels\n",
    "- `predlabels` - prediction labels\n",
    "and returns a table presenting the results\n",
    "\n",
    "See the definition of [Confusion matrix](http://fr.wikipedia.org/wiki/Matrice_de_confusion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(testlabels, predlabels):\n",
    "\n",
    "\tn_classes = max(testlabels)\n",
    "\tmatrix = np.zeros((n_classes,n_classes))\n",
    "\n",
    "\tfor (test,pred) in zip(testlabels, predlabels):\n",
    "\t\tmatrix[test-1,pred-1] += 1\n",
    "\n",
    "\treturn matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `gridplot` takes as input:\n",
    "\n",
    "- `classifier` - a classifier such as `knn`\n",
    "- `train` - a training set\n",
    "- `test` - a test set\n",
    "- `n_points` - the width/height of the grid on which to visualize the decision boundary (n,n)\n",
    "\n",
    "Depending on the speed of your computer, calculating of predictions on the grid can be slow. We recommend doing the first tests with a small grid (say, 25 by 25). You could then augment the size of the grid to 50x50 or even 100x100 to obtain better looking visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function plot\n",
    "def gridplot(classifier,train,test,n_points=50):\n",
    "\n",
    "    train_test = np.vstack((train,test))\n",
    "    (min_x1,max_x1) = (min(train_test[:,0]),max(train_test[:,0]))\n",
    "    (min_x2,max_x2) = (min(train_test[:,1]),max(train_test[:,1]))\n",
    "\n",
    "    xgrid = np.linspace(min_x1,max_x1,num=n_points)\n",
    "    ygrid = np.linspace(min_x2,max_x2,num=n_points)\n",
    "\n",
    "\t# calculates the cartesian product between two lists\n",
    "    # and stores the result in an array\n",
    "    thegrid = np.array(combine(xgrid,ygrid))\n",
    "\n",
    "    counts = classifier.compute_predictions(thegrid)\n",
    "    predictedClasses = np.argmax(counts,axis=1)+1\n",
    "\n",
    "    # The grid\n",
    "    # To get a better looking grid:\n",
    "    #props = dict( alpha=0.3, edgecolors='none' )\n",
    "    #pylab.scatter(thegrid[:,0],thegrid[:,1],c = classesPred, s=50, edgecolors='none')\n",
    "    pylab.pcolormesh(xgrid, ygrid, predictedClasses.reshape((n_points, n_points)).T, alpha=.3)\n",
    "\t# Training data points\n",
    "    pylab.scatter(train[:,0], train[:,1], c = train[:,-1], marker = 'v', s=150)\n",
    "    # Test data points\n",
    "    pylab.scatter(test[:,0], test[:,1], c = test[:,-1], marker = 's', s=150)\n",
    "\n",
    "    ## A hack, since pylab is lacking this functionality... :(\n",
    "    h1 = pylab.plot([min_x1], [min_x2], marker='o', c = 'w',ms=5) \n",
    "    h2 = pylab.plot([min_x1], [min_x2], marker='v', c = 'w',ms=5) \n",
    "    h3 = pylab.plot([min_x1], [min_x2], marker='s', c = 'w',ms=5) \n",
    "    handles = [h1,h2,h3]\n",
    "    ## End of hack :)\n",
    "\n",
    "    labels = ['grid','train','test']\n",
    "    pylab.legend(handles,labels)\n",
    "\n",
    "    pylab.axis('equal')\n",
    "    pylab.show()\n",
    "    \n",
    "## http://code.activestate.com/recipes/302478/\n",
    "def combine(*seqin):\n",
    "    '''returns a list of all combinations of argument sequences.\n",
    "for example: combine((1,2),(3,4)) returns\n",
    "[[1, 3], [1, 4], [2, 3], [2, 4]]'''\n",
    "    def rloop(seqin,listout,comb):\n",
    "        '''recursive looping function'''\n",
    "        if seqin:                       # any more sequences to process?\n",
    "            for item in seqin[0]:\n",
    "                newcomb=comb+[item]     # add next item to current comb\n",
    "                # call rloop w/ rem seqs, newcomb\n",
    "                rloop(seqin[1:],listout,newcomb)\n",
    "        else:                           # processing last sequence\n",
    "            listout.append(comb)        # comb finished, add to list\n",
    "    listout=[]                      # listout initialization\n",
    "    rloop(seqin,listout,[])         # start recursive process\n",
    "    return listout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `knn` takes as parameters:\n",
    "\n",
    "- `n_classes` - the number of classes in the problem\n",
    "- `dist_func` - a function to calculate the distance between points\n",
    "- `n_voisins` - the number of neighbors to visit\n",
    "\n",
    "The method `train` is actually really only storing the dataset. All of the work is done at prediction time for `knn` models.\n",
    "\n",
    "The method `compute_predictions` takes as input the unlabeled test set in matrix form and returns the matrix of counts for each test set example. This matrix is hence of dimensions (n_example, n_classes).\n",
    "\n",
    "You will need to for each test set example:\n",
    "\n",
    " - **calculate distances** for every point of the training set (using dist_func)\n",
    " - Look through the distances to **find the $k$ nearest neighbors** of the current test example\n",
    " - **Calculate the number of neighbors per class** and save them in `counts`\n",
    " \n",
    " **Note :** `knn.compute_predictions()`'s output needs to be general enough to be used in different contexts. This is why we ask that it returns a matrix containing the counts for each example in the test set and not the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class knn:\n",
    "    def __init__(self,n_classes, dist_func=minkowski_mat, nn=1):\n",
    "        self.n_classes = n_classes\n",
    "        self.dist_func = dist_func\n",
    "        self.nn = nn\n",
    "\n",
    "    # The train function for knn is really only storing the dataset\n",
    "    def train(self, train_inputs, train_labels):\n",
    "        self.train_inputs = train_inputs\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    ###\n",
    "    # The prediction function takes as input:\n",
    "    #   test_data - Unlabeled test data points\n",
    "    # and returns a matrix containing counts for each test set example. \n",
    "    # Each row of this matrix contains, for each class, the number of \n",
    "    # neighbors belonging to this class. \n",
    "    ###\n",
    "    def compute_predictions(self, test_data):\n",
    "        # Initialization of the matrix to return\n",
    "        num_test = test_data.shape[0]\n",
    "        counts = np.ones((num_test,self.n_classes))\n",
    "\n",
    "        # For each test datapoint\n",
    "        for (i,ex) in enumerate(test_data):\n",
    "            # i is the row index\n",
    "            # ex is the i'th row\n",
    "\n",
    "            # Find the distances to each training set point\n",
    "            # using dist_func\n",
    "            distances = self.dist_func(ex,self.train_inputs)\n",
    "            # Keep the index of the K nearest neighbors\n",
    "            ind_neighbors = np.argsort(distances)[:self.nn]\n",
    "            # List of the K nearest neighbors\n",
    "            cl_neighbors = list(self.train_labels[ind_neighbors]-1)\n",
    "            \n",
    "            # Calculate the number of neighbors belonging to each class\n",
    "            # and write them in counts[i,:]\n",
    "            # We take the mind of k and data.shape[0] to allow a k greater than the number of examples\n",
    "            for j in range(min(self.nn, self.train_inputs.shape[0])):\n",
    "                cl_neighbors[j]\n",
    "                counts[i]\n",
    "                counts[i,cl_neighbors[j]] += 1\n",
    "\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iris` dataset is divided into two parts, one for training and the other for testing.\n",
    "It is important to shuffle randomly the dataset before splitting it. Can you tell why?\n",
    "\n",
    "Only two columns of the dataset are used to visualize them in 2-dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load iris\n",
    "iris = np.loadtxt('iris.txt')\n",
    "data = iris\n",
    "\n",
    "# Number of classes\n",
    "n_classes = 3\n",
    "# Size of training set\n",
    "n_train = 100\n",
    "\n",
    "# The columns (features) on which to train our model\n",
    "# For gridplot to work, len(train_cols) should be 2\n",
    "train_cols = [0,1]\n",
    "# The index of the column containing the labels\n",
    "target_ind = [data.shape[1] - 1]\n",
    "\n",
    "# Comment to have random (non-deterministic) results \n",
    "random.seed(3395)\n",
    "# Randomly choose indexes for the train and test dataset\n",
    "inds = list(range(data.shape[0]))\n",
    "random.shuffle(inds)\n",
    "train_inds = inds[:n_train]\n",
    "test_inds = inds[n_train:]\n",
    "\n",
    "# Split the data into both sets\n",
    "train_set = data[train_inds,:]\n",
    "train_set = train_set[:,train_cols + target_ind]\n",
    "test_set = data[test_inds,:]\n",
    "test_set = test_set[:,train_cols + target_ind]\n",
    "\n",
    "# Separate the test set into inputs and labels\n",
    "test_inputs = test_set[:,:-1]\n",
    "test_labels = test_set[:,-1].astype('int32')\n",
    "train_inputs = train_set[:, :-1]\n",
    "train_labels = train_set[:, -1].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and training of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take the argmax (class with most votes) of the predictions for each testset example to get a prediction.\n",
    "\n",
    "Don't forget to rerun this cell if you have modified your model and would like to display the decision boundary in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neighbors (k) for knn\n",
    "k = 2\n",
    "print(\"We will train \",k, \"-NN on \", n_train, \" training set examples\")\n",
    "\n",
    "# Create the classifier\n",
    "model = knn(n_classes,dist_func = minkowski_mat, nn = k)\n",
    "# We train the model\n",
    "model.train(train_inputs, train_labels)\n",
    "# We get predictions\n",
    "t1 = time.clock()\n",
    "counts = model.compute_predictions(test_inputs)\n",
    "t2 = time.clock()\n",
    "print('It took ', t2-t1, ' seconds to calculate the predictions on ', test_inputs.shape[0],' test set examples')\n",
    "\n",
    "# Majority vote (+1 since our classes are labeled from 1 to n)\n",
    "classes_pred = np.argmax(counts,axis=1)+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix and decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we print the confusion matrix, which is very useful for analyzing which classes our classifier is having a hard time predicting. We also create a graph displaying the training points as well as the test points and the decision boundary of our model.\n",
    "\n",
    "Before moving on to the next section, please make sure that your $k$-nn implementation works well by executing this code. Do not hesitate to ask questions if you have trouble interpreting the confusion matrix or the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the tests\n",
    "# Confusion Matrix \n",
    "confmat = conf_matrix(test_labels, classes_pred)\n",
    "print('The confusion matrix is:')\n",
    "print(confmat)\n",
    "\n",
    "# Test error\n",
    "sum_preds = np.sum(confmat)\n",
    "sum_correct = np.sum(np.diag(confmat))\n",
    "print(\"The test error is \", 100*(1.0 - (float(sum_correct) / sum_preds)),\"%\")\n",
    "\n",
    "# The grid size will be = grid_size x grid_size\n",
    "grid_size = 200\n",
    "\n",
    "if len(train_cols) == 2:\n",
    "    # Decision boundary\n",
    "    t1 = time.clock()\n",
    "    gridplot(model, train_set, test_set, n_points = grid_size)\n",
    "    t2 = time.clock()\n",
    "    print('It took ', t2-t1, ' seconds to calculate the predictions on', grid_size * grid_size, ' points of the grid')\n",
    "    filename = 'grid_' + '_k=' + str(k) + '_c1=' + str(train_cols[0]) + '_c2=' + str(train_cols[1])+'.png'\n",
    "    print('We will save the plot into {}'.format(filename))\n",
    "    pylab.savefig(filename,format='png')\n",
    "else:\n",
    "    print('Too many dimensions (', len(train_cols),') to print the decision boundary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is working properly, it is time to play with the model in order to better understand the different parameters. Work directly with the code above to run these tests.\n",
    "\n",
    "- Vary the size of `train_set` and `test_set` and observe the impact that it has on the test error and the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Up to you to play with the above code.\n",
    "\n",
    "> You should find that the test set error augments as the training set size decreases. We will always try to have a training set as big as possible in order to get as close as possible to the *real distribution* of the examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try $k=1,2,\\dots,10$.\n",
    "  - Does the test error change?\n",
    "  - Is there an optimal $k$?\n",
    "  - Are you able to tell which $k$ is optimal only by looking at the decision boundary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again, up to you to play with the code.\n",
    "\n",
    "> The test error should change from one $k$ to another. With the same *seed* as in this code, you should find that $k=7$ is optimal.\n",
    "> Observe that the fluctuation of the test error looks like a seesaw (up and down), differing only by a few % between $k$ from 1 to 10 in this case.\n",
    "> It is difficult to see by the decision boundary on the plot which $k$ is optimal. However, the capacity reduction of the model when $k$ augments is visible from the boundary becoming smoother. In other words, as $k$ grows, the representation capacity of the model decreases. The extreme case $k=1$ is an extreme example where the model is able to learn by heart each example in the training set. A large capacity is important in order to be able to represent complex datasets, but it also runs into the danger of overfitting to the training dataset and not generalizing well to the test case, as here in the case $k=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide the training set into 3 parts: `train_set`, `valid_set` and `test_set` (of size 100, 25 and 25, for example). Train $k$-nn on `train_set`, then choose the optimal $k$ using the `valid_set` and finally obtain an estimate of the generalization error of your model by testing on `test_set`. This time, use all 4 features of the dataset. What do you think the validation set is used for?\n",
    "  - Is there a difference between the validation error and the test error for the optimal $k$ found using the validation set? Should there be? (the answer can be found in the question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience(n_train=100,n_valid=25,train_cols=[0,1],ks=[1],seed=3395):\n",
    "\n",
    "    # The index of the columns containing the labels\n",
    "    target_ind = [data.shape[1] - 1]\n",
    "\n",
    "    # Comment to get non-deterministic results. \n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "    # Randomly determine indices for the training and test examples\n",
    "    inds = list(range(data.shape[0]))\n",
    "    random.shuffle(inds)\n",
    "    assert n_train+n_valid < data.shape[0], \"There are no examples left for the test set\"\n",
    "    train_inds = inds[:n_train]\n",
    "    valid_inds = inds[n_train:n_train+n_valid]\n",
    "    test_inds = inds[n_train+n_valid:]\n",
    "\n",
    "    # Separate the data into two sets\n",
    "    train_set = data[train_inds,:]\n",
    "    train_set = train_set[:,train_cols + target_ind]\n",
    "    valid_set = data[valid_inds,:]\n",
    "    valid_set = valid_set[:,train_cols+target_ind]\n",
    "    test_set = data[test_inds,:]\n",
    "    test_set = test_set[:,train_cols + target_ind]\n",
    "    \n",
    "    # Separate the test set into inputs and labels\n",
    "    train_inputs = train_set[:, :-1]\n",
    "    train_labels = train_set[:, -1].astype('int32')\n",
    "    valid_inputs = valid_set[:,:-1]\n",
    "    valid_labels = valid_set[:,-1].astype('int32')\n",
    "    test_inputs = test_set[:,:-1]\n",
    "    test_labels = test_set[:,-1].astype('int32')\n",
    "    \n",
    "    best_result = float('inf')\n",
    "    best_k = 0\n",
    "    best_model = None\n",
    "    for k in ks:\n",
    "        # Create the classifier\n",
    "        model = knn(n_classes,dist_func = minkowski_mat, nn = k)\n",
    "        # Train it\n",
    "        model.train(train_inputs, train_labels)\n",
    "        # Get its predictions\n",
    "        counts = model.compute_predictions(valid_inputs)\n",
    "\n",
    "        # Majority vote (+1 since our classes are labeled from 1 to n)\n",
    "        classes_pred = np.argmax(counts,axis=1)+1\n",
    "        \n",
    "        result = (1.0-(valid_labels==classes_pred).mean())\n",
    "        \n",
    "        if result < best_result:\n",
    "            best_model = model\n",
    "            best_k = k\n",
    "            best_result = result\n",
    "    \n",
    "    return train_set, valid_set, test_set, best_model, best_k\n",
    "    \n",
    "def graphics(train_set, valid_set, test_set, model):\n",
    "\n",
    "    valid_inputs = valid_set[:,:-1]\n",
    "    test_inputs = test_set[:,:-1]\n",
    "    valid_labels = valid_set[:,-1].astype('int32')\n",
    "    test_labels = test_set[:,-1].astype('int32')\n",
    "    \n",
    "    counts = model.compute_predictions(valid_inputs)\n",
    "    valid_pred = np.argmax(counts,axis=1)+1\n",
    "    counts = model.compute_predictions(test_inputs)\n",
    "    test_pred = np.argmax(counts,axis=1)+1    \n",
    "    \n",
    "    # Confusion Matrix\n",
    "    confmat = conf_matrix(valid_labels, valid_pred)\n",
    "    print(\"The confusion matrix for the validation set is:\")\n",
    "    print(confmat)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    confmat = conf_matrix(test_labels, test_pred)\n",
    "    print(\"The confusion matrix for the test set is:\")\n",
    "    print(confmat)\n",
    "\n",
    "    # Validation error\n",
    "    print(\"The validation error is \", 100.*(1.0 - (valid_labels==valid_pred)).mean(),\"%\")\n",
    "    \n",
    "    # Erreur de test\n",
    "    print(\"The test error is \", 100.*(1.0 - (test_labels==test_pred)).mean(),\"%\")\n",
    "\n",
    "    # Size of the grid = grid_size x grid_size\n",
    "    grid_size = 200\n",
    "\n",
    "    if len(train_cols) == 2:\n",
    "        # Decision boundary\n",
    "        gridplot(model,train_set,test_set,n_points = grid_size)\n",
    "        print('We will save the plot into {}'.format(filename))\n",
    "        pylab.savefig(filename,format='png')\n",
    "    else:\n",
    "        print('Too many dimensions (', len(train_cols),') to display the decision boundary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set, best_model, best_k = experience(n_train=100,n_valid=25,train_cols=[0,1],ks=list(range(1,100)))\n",
    "print(\"The best k is {}\".format(best_k))\n",
    "graphics(train_set, valid_set, test_set, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uncomment the line `random.seed(3395)` and run your code multiple times to get statistics on the validation and test errors. You can write a `for` loop to execute the same piece of code multiple times; 10 times should be enough. Calculate the mean and standard deviation for each error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "results = np.zeros(N)\n",
    "# We test the model N times on the same dataset\n",
    "for i in range(N):\n",
    "    train_set, valid_set, test_set, best_model, best_k = experience(n_train=100,n_valid=25,train_cols=[0,1],ks=[7],seed=False)\n",
    "    \n",
    "    test_inputs = test_set[:,:-1]\n",
    "    test_labels = test_set[:,-1].astype('int32')\n",
    "    \n",
    "    counts = model.compute_predictions(test_inputs)\n",
    "    test_pred = np.argmax(counts,axis=1)+1    \n",
    "    \n",
    "    # Test error\n",
    "    results[i] = 100.*(1.0 - (test_labels==test_pred)).mean()\n",
    "\n",
    "# The standard deviation is considerably large considering the mean error\n",
    "# We see that the seed is important for reproducibility of the experiments\n",
    "print(results)\n",
    "print(\"Moyenne \", results.mean())\n",
    "print(\"Écart-type \", results.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
