%&pdflatex
%% filename: amsart-template.tex, version: 2.1
\documentclass{amsart}
\usepackage{amscd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{bbold}
\usepackage{bm}
\usepackage{fontenc}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{inputenc}
\usepackage{mathrsfs}
\usepackage{mathtools}

\hypersetup{linkcolor=blue,citecolor=red,filecolor=dullmagenta,urlcolor=blue}

\newtheorem{conj}{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{definition}{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}{Notation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{xca}[theorem]{Exercise}
\numberwithin{equation}{section}
\setlength{\parindent}{0pt} % turn off auto-indent
\theoremstyle{definition}
\theoremstyle{remark}

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
\newcommand{\bnxk}{{\mathrm{N}}(x,k)}
\newcommand{\pd}{\frac{\partial}{\partial}}
\newcommand{\px}[1]{\pi(x,{#1})}
\newcommand{\Px}[1]{\Pi(x,{#1})}
\newcommand{\snxk}{\pi(x,k)}

\graphicspath{ {./} }

\begin{document}

\title{Assignment 4: Theory of Generative Models [IFT6135]}

\author{Joseph D. Viviano}
\address{Universit\'e de Montr\'eal}
\curraddr{}
\email{joseph@viviano.ca}
\thanks{}
\date{April 2018}

\maketitle

\section{Reparameterization Trick of Variational Autoencoders} \\

\subsection{Transformation of Gaussian Noise} \\

\subsection{Encoders vs. Mean Fields} \\

\section{Importance Weighted Autoencoder} \\

\subsection{IWLB as a Lower Bound on log Likelihood} \\

\subsection{IWLB with k=2 is tighter than ELBO with k=1} \\

\section{Maximum Likelihood for Generative Adversarial Networks} \\

The original GAN objective can be writen as: \\

$$ \max_D \mathbf{E}_{p}_{D}(x)} \big[\log D(x)\big] + \mathbf{E}_{p_G} \big[\log (1 - D(G(z))) \big]; \quad \max_G \mathbf{E}_{p_G} \big[\log D(G(z)) \big] $$ \\

Note that the definition of an optimial discriminator using this notation is: \\

\begin{equation}
D^*(\mathbf{x}) = \frac{p_D(\mathbf{x})}{p_G(\mathbf{x}) + p_D(\mathbf{x})} \\
\end{equation} \\

The goal here is to find the maximum likelihood objective (cost function) instead of the negative log liklihood objective to apply to samples coming from the generator $\mathbf{E}_{p_G} \big[f(D(G(z))) \big]$, where $f(D(G(z)))$ must be found. \\

As a reminder, the maximum likelihood estimate in this case would be: \\

$$\hat\theta \in \{ \underset{\theta\in\Theta}{\operatorname{arg\,max}}\ \mathcal f(\theta\,;x) \}$$ \\

Each step of learning in a GAN consists of reducing the expectation $f(x)$ run on a bunch of samples pulled from generator $G$, which we express as \\ 

\begin{equation}
\mathbf{E}_{x ~ p_G} f(x)
\end{equation} \\

here, $p_G$ represents a sample pulled from the probability distribution generated by $G$. First, let's take partial derivative with respect to the weights $\theta$ on a sample $x ~ p_G$ from the generator and represent it as an integral. Then we applied Leibniz's rule, and sub in the identity $ \frac{\partial}{\partial \theta}p_G(x) = p_G(x) \frac{\partial}{\partial \theta} log p_G(x)$: \\

\begin{equation}
\begin{aligned}
& \frac{\partial}{\partial \theta} \mathbf{E}_{x ~ p_G} f(x) = \int f(x) \frac{\partial}{\partial \theta} p_G(x) \\
& = \int f(x) \frac{\partial}{\partial \theta} p_G (X) dx \\
& = \int f(x) p_G(x) \frac{\partial}{\partial \theta} log {p_G}(x) \\
\end{aligned}
\end{equation}\\


While tells us that we can express the aformentioned expectation (3.2) as: \\

\begin{equation}
\mathbf{E}_{x ~ p_G} f(x) \frac{\partial}{\partial \theta} log {p_G}(x)
\end{equation} \\

This tells us the maximum likelihood can be found given: \\

\begin{equation}
f(x) = - \frac{p_D(x)}{p_G{x}}
\end{equation} \\

Now if we assume that our optimal discriminator $D^*(\mathbf{x})$ from (3.1) is the logistic sigmoid $\sigma(a(x))$ then \\

\begin{equation}
\sigma(a(x)) = \frac{p_D(\mathbf{x})}{p_G(\mathbf{x}) + p_D(\mathbf{x})}
\end{equation} \\

And it follows that \\

\begin{equation}
f(x) = -\exp(a(x))
\end{equation} \\

which is our function $f$ such that the objective corresponds to maximum liklihood.

%$$\frac{\partial}{\partial \theta}$ J^{(G)} = \mathbf{E}_{x ~ p_g} f(x) \frac{\partial}{\partial \theta} log p_g(x)$$

\end{document}

